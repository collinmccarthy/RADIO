------------------------------------------------------------
Radio Version: e-radio_v2, Model: eradio, Num Params: 389.60M
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Resource kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'url': 'https://huggingface.co/nvidia/RADIO/resolve/main/eradio_v2.pth.tar?download=true',
 'patch_size': 16,
 'max_resolution': 2048,
 'preferred_resolution': {'height': 512, 'width': 512},
 'vitdet_num_windowed': None,
 'vitdet_num_global': None}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Conditioner kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'input_scale': 1.0,
 'norm_mean': (0.48145466, 0.4578275, 0.40821073),
 'norm_std': (0.26862954, 0.26130258, 0.27577711),
 'dtype': torch.float32}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Create model kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'model': 'eradio',
 'in_chans': None,
 'input_size': None,
 'pretrained': False,
 'num_classes': None,
 'drop': 0.0,
 'drop_path': None,
 'drop_block': None,
 'gp': None,
 'bn_momentum': None,
 'bn_eps': None,
 'initial_checkpoint': '',
 'torchscript': False,
 'cls_token_per_teacher': False,
 'cpe_max_size': None,
 'model_kwargs': {'return_full_features': True},
 'teachers': [{'type': 'open_clip',
               'name': 'clip',
               'model': 'ViT-H-14-378-quickgelu',
               'pretrained': 'dfn5b',
               'feature_distillation': True,
               'fd_normalize': False,
               'input_size': 378},
              {'type': 'dino_v2',
               'name': 'dino_v2',
               'model': 'dinov2_vitg14_reg',
               'feature_distillation': True,
               'fd_normalize': False,
               'input_size': 224},
              {'type': 'dino_v2',
               'name': 'dino_v2_large',
               'model': 'dinov2_vitl14_reg',
               'feature_distillation': True,
               'fd_normalize': False,
               'input_size': 448},
              {'type': 'sam',
               'name': 'sam',
               'model': 'vit-h',
               'feature_distillation': True,
               'fd_normalize': False,
               'input_size': 1024}],
 'register_multiple': 0,
 'spectral_reparam': False,
 'model_norm': False}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Radio kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'patch_size': 16,
 'max_resolution': 2048,
 'preferred_resolution': Resolution(height=512, width=512),
 'summary_idxs': tensor([0, 1, 2, 3]),
 'window_size': None,
 'adaptors': {}}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Configurable radio kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'patch_size': 16,
 'max_resolution': 2048,
 'preferred_resolution': Resolution(height=512, width=512),
 'adaptor_cfgs': None,
 'vitdet_window_size': None,
 'vitdet_num_windowed': None,
 'vitdet_num_global': None,
 'create_model_kwargs': {'model': 'eradio',
                         'in_chans': None,
                         'input_size': None,
                         'pretrained': False,
                         'num_classes': None,
                         'drop': 0.0,
                         'drop_path': None,
                         'drop_block': None,
                         'gp': None,
                         'bn_momentum': None,
                         'bn_eps': None,
                         'initial_checkpoint': '',
                         'torchscript': False,
                         'cls_token_per_teacher': False,
                         'cpe_max_size': None,
                         'model_kwargs': {'return_full_features': True},
                         'teachers': [{'type': 'open_clip',
                                       'name': 'clip',
                                       'model': 'ViT-H-14-378-quickgelu',
                                       'pretrained': 'dfn5b',
                                       'feature_distillation': True,
                                       'fd_normalize': False,
                                       'input_size': 378},
                                      {'type': 'dino_v2',
                                       'name': 'dino_v2',
                                       'model': 'dinov2_vitg14_reg',
                                       'feature_distillation': True,
                                       'fd_normalize': False,
                                       'input_size': 224},
                                      {'type': 'dino_v2',
                                       'name': 'dino_v2_large',
                                       'model': 'dinov2_vitl14_reg',
                                       'feature_distillation': True,
                                       'fd_normalize': False,
                                       'input_size': 448},
                                      {'type': 'sam',
                                       'name': 'sam',
                                       'model': 'vit-h',
                                       'feature_distillation': True,
                                       'fd_normalize': False,
                                       'input_size': 1024}],
                         'register_multiple': 0,
                         'spectral_reparam': False,
                         'model_norm': False},
 'dtype': torch.float32,
 'input_scale': 1.0,
 'norm_mean': (0.48145466, 0.4578275, 0.40821073),
 'norm_std': (0.26862954, 0.26130258, 0.27577711),
 'cast_outputs_to_fp32': True,
 'disable_spectral_reparam': True,
 'ignore_teachers': False,
 'pretrained_url': 'https://huggingface.co/nvidia/RADIO/resolve/main/eradio_v2.pth.tar?download=true',
 'out_indices_layers': None,
 'out_indices_stages': None}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Full checkpoint kwargs
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
{'aa': None,
 'amp': True,
 'amp_dtype': 'bfloat16',
 'amp_impl': 'native',
 'aug_repeats': 0,
 'aug_splits': 0,
 'bn_eps': None,
 'bn_momentum': None,
 'cache_dir': None,
 'channels_last': False,
 'checkpoint_hist': 10,
 'chk_keep_forever': 10,
 'class_map': '',
 'clip_grad': None,
 'clip_mode': 'norm',
 'cls_token_per_teacher': False,
 'coco_annotations_file': '/datasets/coco2017-adlsa/annotations/captions_val2017.json',
 'coco_image_dir': '/datasets/coco2017-adlsa/val2017',
 'color_jitter': 0.4,
 'cooldown_epochs': 0,
 'cpe_max_size': None,
 'crd_loss': False,
 'crd_loss_weight': 0.8,
 'crop_pct': None,
 'cutmix': 0.0,
 'cutmix_minmax': None,
 'dataset_download': False,
 'ddp_comm_fp16': False,
 'ddp_comm_power_sgd': False,
 'debug_full_knn': False,
 'decay_epochs': 90,
 'decay_milestones': [90, 180, 270],
 'decay_rate': 0.1,
 'device': 'cuda:0',
 'dist_bn': '',
 'distributed': True,
 'drop': 0.0,
 'drop_block': None,
 'drop_connect': None,
 'drop_path': None,
 'dtype': torch.float32,
 'epoch_repeats': 0.0,
 'eval': False,
 'eval_metric': 'knn_top1',
 'eval_teacher': False,
 'eval_teacher_only': False,
 'eval_throughput': False,
 'fast_norm': False,
 'feature_summarizer': 'cls_token',
 'feature_upscale_factor': None,
 'force_new_wandb_id': False,
 'force_spectral_reparam': False,
 'freeze_bn': False,
 'fuser': '',
 'gp': None,
 'grad_accum_steps': 1,
 'grad_checkpointing': False,
 'head_init_bias': None,
 'head_init_scale': None,
 'head_warmup': 10,
 'hflip': 0.5,
 'img_size': None,
 'in_chans': None,
 'initial_checkpoint': '',
 'input_size': None,
 'interpolation': '',
 'layer_decay': None,
 'local_rank': 0,
 'log_interval': 50,
 'log_mlflow': False,
 'log_wandb': True,
 'loss_auto_balance': False,
 'lr_base': 0.1,
 'lr_base_scale': '',
 'lr_base_size': 256,
 'lr_cycle_decay': 0.5,
 'lr_cycle_limit': 1,
 'lr_cycle_mul': 1.0,
 'lr_k_decay': 1.0,
 'lr_noise': None,
 'lr_noise_pct': 0.67,
 'lr_noise_std': 1.0,
 'mean': None,
 'mesa': False,
 'min_lr': 0,
 'mixup': 0.0,
 'mixup_mode': 'batch',
 'mixup_off_epoch': 0,
 'mixup_prob': 1.0,
 'mixup_switch_prob': 0.5,
 'mlp_hidden_size': 1520,
 'mlp_num_inner': 1,
 'mlp_version': 'v2',
 'model': 'eradio',
 'model_kwargs': {'return_full_features': True},
 'model_norm': False,
 'momentum': 0.9,
 'no_aug': False,
 'no_ddp_bb': False,
 'no_prefetcher': False,
 'no_resume_opt': False,
 'num_classes': None,
 'opt_betas': None,
 'opt_eps': None,
 'patience_epochs': 10,
 'pin_mem': False,
 'prefetcher': True,
 'pretrained': False,
 'rank': 0,
 'ratio': [0.75, 1.3333333333333333],
 'recount': 1,
 'recovery_interval': 0,
 'register_multiple': 0,
 'remode': 'pixel',
 'reprob': 0.0,
 'resplit': False,
 'save_images': False,
 'scale': [0.5, 1.0],
 'sched': 'cosine',
 'seed': 42,
 'smoothing': 0.1,
 'spectral_reparam': False,
 'split_bn': False,
 'start_epoch': None,
 'std': None,
 'sync_bn': True,
 'synchronize_step': True,
 'teachers': [{'fd_normalize': False,
               'feature_distillation': True,
               'input_size': 378,
               'model': 'ViT-H-14-378-quickgelu',
               'name': 'clip',
               'pretrained': 'dfn5b',
               'type': 'open_clip'},
              {'fd_normalize': False,
               'feature_distillation': True,
               'input_size': 224,
               'model': 'dinov2_vitg14_reg',
               'name': 'dino_v2',
               'type': 'dino_v2'},
              {'fd_normalize': False,
               'feature_distillation': True,
               'input_size': 448,
               'model': 'dinov2_vitl14_reg',
               'name': 'dino_v2_large',
               'type': 'dino_v2'},
              {'fd_normalize': False,
               'feature_distillation': True,
               'input_size': 1024,
               'model': 'vit-h',
               'name': 'sam',
               'type': 'sam'}],
 'torchcompile': None,
 'torchscript': False,
 'train_interpolation': 'random',
 'train_split': 'train',
 'tta': 0,
 'use_coco': False,
 'use_multi_epochs_loader': False,
 'val_ema_only': False,
 'val_split': 'val',
 'vflip': 0.0,
 'wandb_entity': '',
 'wandb_job_type': '',
 'wandb_name': '',
 'wandb_project': '',
 'warmup_lr': 1e-05,
 'warmup_prefix': False,
 'worker_seeding': 'all',
 'workers': 10,
 'world_size': 64}
************************************************************
Verification: FAILED
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 
Error message 1 of 1
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 
Diff for RADIOModel with version 'e-radio_v2' failed. Torchhub version and HuggingFace version using repo id 'NVIDIA/E-RADIO' produced different results. Diff results:
{'<self>': {'buffers': {'summary_idxs': {'shape': {'orig_shape': torch.Size([4]),
                                                   'curr_shape': torch.Size([3])}}}},
 'model.levels.2.blocks.0.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.0.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(601),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.1146),
                                                                                                                                                                          'numel_compare_false': tensor(523687),
                                                                                                                                                                          'numel_compare_false_perc': tensor(99.8854),
                                                                                                                                                                          'curr_mean': tensor(6.2899),
                                                                                                                                                                          'orig_mean': tensor(6.2875)}}}},
 'model.levels.2.blocks.0.attention_blocks.1.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.0.attention_blocks.1.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(524288),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(11.9674),
                                                                                                                                                                          'orig_mean': tensor(11.9665)}}}},
 'model.levels.2.blocks.1.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.1.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(97109),
                                                                                                                                                                          'numel_compare_true_perc': tensor(18.5221),
                                                                                                                                                                          'numel_compare_false': tensor(427179),
                                                                                                                                                                          'numel_compare_false_perc': tensor(81.4779),
                                                                                                                                                                          'curr_mean': tensor(14.5288),
                                                                                                                                                                          'orig_mean': tensor(14.5258)}}}},
 'model.levels.2.blocks.1.attention_blocks.1.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.1.attention_blocks.1.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(524288),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(6.8442),
                                                                                                                                                                          'orig_mean': tensor(6.8446)}}}},
 'model.levels.2.blocks.2.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.2.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(4616),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.8804),
                                                                                                                                                                          'numel_compare_false': tensor(519672),
                                                                                                                                                                          'numel_compare_false_perc': tensor(99.1196),
                                                                                                                                                                          'curr_mean': tensor(11.9702),
                                                                                                                                                                          'orig_mean': tensor(11.9721)}}}},
 'model.levels.2.blocks.2.attention_blocks.1.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.2.attention_blocks.1.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(524288),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(4.4389),
                                                                                                                                                                          'orig_mean': tensor(4.4383)}}}},
 'model.levels.2.blocks.3.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.3.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(120003),
                                                                                                                                                                          'numel_compare_true_perc': tensor(22.8888),
                                                                                                                                                                          'numel_compare_false': tensor(404285),
                                                                                                                                                                          'numel_compare_false_perc': tensor(77.1112),
                                                                                                                                                                          'curr_mean': tensor(12.0263),
                                                                                                                                                                          'orig_mean': tensor(12.0269)}}}},
 'model.levels.2.blocks.3.attention_blocks.1.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.3.attention_blocks.1.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(524288),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(5.5645),
                                                                                                                                                                          'orig_mean': tensor(5.5655)}}}},
 'model.levels.2.blocks.4.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.4.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(18395),
                                                                                                                                                                          'numel_compare_true_perc': tensor(3.5086),
                                                                                                                                                                          'numel_compare_false': tensor(505893),
                                                                                                                                                                          'numel_compare_false_perc': tensor(96.4914),
                                                                                                                                                                          'curr_mean': tensor(9.9937),
                                                                                                                                                                          'orig_mean': tensor(9.9949)}}}},
 'model.levels.2.blocks.4.attention_blocks.1.attn.pos_emb_funct': {'buffers': {'model.levels.2.blocks.4.attention_blocks.1.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(524288),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(0.9461),
                                                                                                                                                                          'orig_mean': tensor(0.9475)}}}},
 'model.levels.3.blocks.0.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.3.blocks.0.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(1048576),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(5.6395),
                                                                                                                                                                          'orig_mean': tensor(5.6406)}}}},
 'model.levels.3.blocks.1.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.3.blocks.1.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(3376),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.3220),
                                                                                                                                                                          'numel_compare_false': tensor(1045200),
                                                                                                                                                                          'numel_compare_false_perc': tensor(99.6780),
                                                                                                                                                                          'curr_mean': tensor(5.1782),
                                                                                                                                                                          'orig_mean': tensor(5.1798)}}}},
 'model.levels.3.blocks.2.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.3.blocks.2.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(0),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.),
                                                                                                                                                                          'numel_compare_false': tensor(1048576),
                                                                                                                                                                          'numel_compare_false_perc': tensor(100.),
                                                                                                                                                                          'curr_mean': tensor(10.8160),
                                                                                                                                                                          'orig_mean': tensor(10.8165)}}}},
 'model.levels.3.blocks.3.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.3.blocks.3.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(5347),
                                                                                                                                                                          'numel_compare_true_perc': tensor(0.5099),
                                                                                                                                                                          'numel_compare_false': tensor(1043229),
                                                                                                                                                                          'numel_compare_false_perc': tensor(99.4901),
                                                                                                                                                                          'curr_mean': tensor(14.9664),
                                                                                                                                                                          'orig_mean': tensor(14.9700)}}}},
 'model.levels.3.blocks.4.attention_blocks.0.attn.pos_emb_funct': {'buffers': {'model.levels.3.blocks.4.attention_blocks.0.attn.pos_emb_funct.relative_bias': {'values': {'numel_compare_true': tensor(51909),
                                                                                                                                                                          'numel_compare_true_perc': tensor(4.9504),
                                                                                                                                                                          'numel_compare_false': tensor(996667),
                                                                                                                                                                          'numel_compare_false_perc': tensor(95.0496),
                                                                                                                                                                          'curr_mean': tensor(3.0882),
                                                                                                                                                                          'orig_mean': tensor(3.0878)}}}},
 'forward_eval_deploy_exact': {'summary': {'values': {'numel_compare_true': tensor(0),
                                                      'numel_compare_true_perc': tensor(0.),
                                                      'numel_compare_false': tensor(1536),
                                                      'numel_compare_false_perc': tensor(100.),
                                                      'curr_mean': tensor(-0.0026),
                                                      'orig_mean': tensor(-0.0026)}},
                               'features': {'values': {'numel_compare_true': tensor(6),
                                                       'numel_compare_true_perc': tensor(0.0004),
                                                       'numel_compare_false': tensor(1572858),
                                                       'numel_compare_false_perc': tensor(99.9996),
                                                       'curr_mean': tensor(-0.0026),
                                                       'orig_mean': tensor(-0.0026)}}},
 'forward_eval_deploy_allclose': {'summary': {'values': {'numel_compare_true': tensor(10),
                                                         'numel_compare_true_perc': tensor(0.6510),
                                                         'numel_compare_false': tensor(1526),
                                                         'numel_compare_false_perc': tensor(99.3490),
                                                         'curr_mean': tensor(-0.0026),
                                                         'orig_mean': tensor(-0.0026)}},
                                  'features': {'values': {'numel_compare_true': tensor(2676),
                                                          'numel_compare_true_perc': tensor(0.1701),
                                                          'numel_compare_false': tensor(1570188),
                                                          'numel_compare_false_perc': tensor(99.8299),
                                                          'curr_mean': tensor(-0.0026),
                                                          'orig_mean': tensor(-0.0026)}}}}
************************************************************
